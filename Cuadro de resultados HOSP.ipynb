{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center><font size = 5>Machine Learning models for aiding the decision-making process in emergency departments</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Tabla comparativa de algoritmos<h1>\n",
    "<h3>Descripción</h3>\n",
    "<p>\n",
    "En este script se desarrollará una serie de predicciones basadas en datos del hospital San Juan de Dios Curicó, correspondientes al año 2018 representados por registros de urgencias. El objetivo es predecir, mediante un conjunto de algoritmos, la necesidad de hospitalización de un paciente de urgencias,tomando como input, datos proporcionados por el paciente en la etapa de registro, sus signos vitales registrados en la etapa de triage y el diagnóstico ofrecido por el médico tratante.\n",
    "Se correrán algoritmos de prodicción tales como árboles y bosques de desición, regresión logística, support vector machines y redes neuronales. Para finalmente evaluar el rendimiento de cada algoritmo en términos de la predicción, mediante indicadores tales como Acuraccy, F1-Score, Curva ROC, Índice de Jaccard y logloss\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Descripción de datos\">Descripción de datos</h1>\n",
    "<p>\n",
    "Los datos utilizados fueros proporcionados por el Hospital San Juan de Dios, Curicó, Chile y corresponden a 4.971 registros de pacientes que asistieron a urgencias durante el periodo comprendido entre el 1 de enero de 2018 y agosto de 2019, los datos fueron limpiados y transformados en un script desarrollado previamente\n",
    "<ul>\n",
    "    <li>Datos: <a href=\"https://drive.google.com/open?id=1Bp7_MnK6cGwgBuwIq1a8S4DS_0wVDiAD\" target=\"_blank\">https://drive.google.com/open?id=1Bp7_MnK6cGwgBuwIq1a8S4DS_0wVDiAD</a></li>\n",
    "    <li>Tipo de datos: csv</li>\n",
    "   </ul>\n",
    "<p>\n",
    "Las variables presentes en los datos se describen a continuación:\n",
    "<ul>    \n",
    "   \n",
    "   <li><b>PAC_EDAD</b>: corresponde a la edad del paciente en enteros</li>\n",
    "   <li><b>MOTIVO_CONSULTA</b>: corresponde a la razón por la que el paciente acude al servicio de urgencias string</li>\n",
    "   <li><b>MEDIO</b>: corresponde al medio de llegada, mediante el que el paciente acude al servicio de urgencias</li>\n",
    "   <li><b>SEXO</b>: corresponde al sexo del paciente</li>\n",
    "   <li><b>CAT</b>: corresponde a la categoría de gravedad asignada al paciente en el proceso de Triage</li>\n",
    "   <li><b>PRESION_SIST</b>: corresponde la presión sistólica del paciente </li>\n",
    "   <li><b>PRESION_DIAST</b>: corresponde la presióndiastólica del paciente</li>\n",
    "   <li><b>SATO2</b>: Dato numérico que representa la saturometria del paciente (Nivel de oxigeno en la sangre)</li>\n",
    "   <li><b>TEMPERATURA</b>: corresponde a la temperatura corporal del paciente en el momento de la categorización</li>\n",
    "   <li><b>GLASGOW</b>: corresponde a al nivel registrado por el paciente en la escala Glasgow</li>\n",
    "   <li><b>DM</b>: corresponde si el paciente presenta o no Diabetes Mellitus</li>\n",
    "   <li><b>EVA</b>: corresponde si se aplica al paciente una evaluación de vias aéreas</li>\n",
    "   <li><b>HGT</b>: corresponde a la medida de azucar en la sangre del paciente</li>\n",
    "   <li><b>LCFA</b>: corresponde a si el paciente presenta obstrucción crónica de vías aéreas</li>\n",
    "   <li><b>FR</b>: corresponde a la frecuencia respiratoria del paciente</li>\n",
    "   <li><b>HTA</b>: corresponde a si el paciente posee Hipertención Arterial</li>\n",
    "   <li><b>HORA_INSC</b>: corresponde a la hora en la que el paciente fue categorizado</li>\n",
    "   <li><b>MIN_INSC</b>: corresponde al minuto en que el paciente fue categorizado</li>\n",
    "   <li><b>TIEMPO_ESPERA_CAT</b>: corresponde al tiempo que espera el paciente luego de ser registrado, para ser categorizado</li>\n",
    "      \n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "import sklearn as sk  \n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "#from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import f1_score\n",
    "#Métodos de tuneo de parámetros\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo= 'df_definitiva_B.csv'\n",
    "df_hosp= pd.read_csv(archivo,encoding='latin-1',sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo='df_cat_soloTexto.csv'\n",
    "df_cat= pd.read_csv(archivo,encoding='latin-1',sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hosp =df_hosp[['ID_PACIENTE','DESTINO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.columns\n",
    "df_cat.drop(columns =['DESC_EVENTO','CAT'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unión de bases de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hosp =  df_hosp.join(df_cat, lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiando de faltantes las columnas\n",
    "df_hosp.dropna(subset=[\"ID_PACIENTE_caller\"], axis=0, inplace = True)\n",
    "df_hosp.dropna(subset=[\"ID_PACIENTE_other\"], axis=0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hosp.drop(columns =['Unnamed: 0'], inplace = True)\n",
    "df_cat.drop(columns =['Unnamed: 0'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hosp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiando de faltantes las columnas\n",
    "df_hosp.dropna(subset=[\"DESTINO\"], axis=0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quitando ID_PACIENTE\n",
    "df_hosp.drop(columns =[\"ID_PACIENTE_caller\"], inplace = True)\n",
    "df_hosp.drop(columns =[\"ID_PACIENTE_other\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =df_hosp['DESTINO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quitando 'DESTINO'\n",
    "#df_hosp.drop(columns =['DESTINO'], inplace = True)\n",
    "#df_hosp.drop(columns =['CAT'], inplace = True)\n",
    "df_hosp.drop(columns =['DESTINO'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = df_hosp.isnull()\n",
    "\n",
    "    \n",
    "for column in missing_data.columns.values.tolist():\n",
    "    print(column)\n",
    "    print (missing_data[column].value_counts())\n",
    "    print(\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionar las variables relevantes para la predicción y asignarselas a la matriz X, de variables independientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_hosp\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1 id=\"Normalización de datos\">Normalización de datos</h1>\n",
    "<p>\n",
    "Para aplicar el paquete de arboles de desición, los datos deben estar en una escala similar, es por ello que optamos por normalizarlos para que los valores estén en un rango entre -2 y 2. Esta medida no altera los resultados aunque si faborece a la eficiencia de los algoritmos\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1 id=\"Configurando algoritmos\">Configurando algoritmos</h1>\n",
    "<p>\n",
    "En esta sección se definen parámetros necesarios para la correcta aplicación de los algoritmos a implementar, además de seccionar el conjunto de datos en datos de prueba(30%)y de entrenamiento (70%). Los parámetros escogidos pueden ser modificados con el fin de obtener resultados diferentes\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentación del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampling del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from collections import Counter\n",
    " \n",
    "os_us = SMOTETomek(sampling_strategy='auto',random_state=None,smote=None,tomek=None,n_jobs=None,)\n",
    "X_trainset_res_ST1, y_trainset_res_ST1 = os_us.fit_sample(X_trainset, y_trainset)\n",
    " \n",
    "print (\"Distribution before resampling {}\".format(Counter(y_trainset)))\n",
    "print (\"Distribution labels after resampling {}\".format(Counter(y_trainset_res_ST1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Árbol de desición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT= DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n",
    "DT.fit(X_trainset,y_trainset)\n",
    "yhat_1 = DT.predict(X_testset)\n",
    "yhat_prob_1=DT.predict_proba(X_testset)\n",
    "DT_Acc=round(metrics.accuracy_score(y_testset, yhat_1),4)\n",
    "#DT_Jcc=round(jaccard_similarity_score(y_testset, yhat_1),4)\n",
    "DT_lgl=round(log_loss(y_testset, yhat_prob_1),4)\n",
    "DT_F1=f1_score(y_testset, yhat_1, average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_GS = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
    "                       max_depth=19, max_features=None, max_leaf_nodes=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0,\n",
    "                       random_state=42, splitter='best')\n",
    "DT_GS.fit(X_trainset,y_trainset)\n",
    "DT_GS_ST=DT_GS.fit(X_trainset_res_ST1, y_trainset_res_ST1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_parameters = [{'criterion': ['entropy', 'gini'], 'max_depth': np.arange(3, 21)},{'min_samples_leaf': [5, 10, 20, 50, 100]}]\n",
    "DT_GS = GridSearchCV(DecisionTreeClassifier(random_state=42), DT_parameters, verbose=1, cv=5, scoring='balanced_accuracy')\n",
    "DT_GS.fit(X_trainset,y_trainset)\n",
    "DT_GS_ST=DT_GS.fit(X_trainset_res_ST1, y_trainset_res_ST1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_1_GS= DT_GS.predict(X_testset)\n",
    "yhat_prob_1_GS=DT_GS.predict_proba(X_testset)\n",
    "DT_Acc_GS=round(metrics.accuracy_score(y_testset, yhat_1_GS),4)\n",
    "#DT_Jcc_GS=round(jaccard_similarity_score(y_testset, yhat_1_GS),4)\n",
    "DT_lgl_GS=round(log_loss(y_testset, yhat_prob_1_GS),4)\n",
    "DT_F1_GS=round(f1_score(y_testset, yhat_1_GS, average='weighted'),4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_1_GS_ST= DT_GS_ST.predict(X_testset)\n",
    "yhat_prob_1_GS=DT_GS.predict_proba(X_testset)\n",
    "DT_Acc_GS_ST=round(metrics.accuracy_score(y_testset, yhat_1_GS_ST),4)\n",
    "#DT_Jcc_GS_ST=round(jaccard_similarity_score(y_testset, yhat_1_GS_ST),4)\n",
    "#DT_lgl_GS=round(log_loss(y_testset, yhat_prob_1_GS_ST),4)\n",
    "DT_F1_GS_ST=round(f1_score(y_testset, yhat_1_GS_ST, average='weighted'),4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_DT = {'índices de rendimiento':['Accuracy','F1-Score'],\n",
    "             'Árboles de decisión':[DT_Acc,DT_F1],\n",
    "             'Grid Search':[DT_Acc_GS,DT_F1_GS],\n",
    "                'GS+SMOTE-Tomek':[DT_Acc_GS_ST,DT_F1_GS_ST]}\n",
    "Tabla_resultados_DT=pd.DataFrame(resultados_DT)\n",
    "print(Tabla_resultados_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_hosp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = PermutationImportance(DT, random_state=1).fit(X, y)\n",
    "eli5.show_weights(perm, feature_names =X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "ex = shap.TreeExplainer(DT)\n",
    "shap_values = ex.shap_values(X)\n",
    "shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bosque de desición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF= RandomForestClassifier(max_depth=2, random_state=0)\n",
    "RF.fit(X_trainset,y_trainset)\n",
    "yhat_2 = RF.predict(X_testset)\n",
    "yhat_prob_2=RF.predict_proba(X_testset)\n",
    "RF_Acc=round(metrics.accuracy_score(y_testset, yhat_2),4)\n",
    "#RF_Jcc=round(jaccard_similarity_score(y_testset, yhat_2),4)\n",
    "RF_lgl=round(log_loss(y_testset, yhat_prob_2),4)\n",
    "RF_F1=f1_score(y_testset, yhat_2, average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_GS =RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=20, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=400,\n",
    "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
    "                       warm_start=False)\n",
    "RF_GS.fit(X_trainset,y_trainset)\n",
    "DT_GS_ST=DT_GS.fit(X_trainset_res_ST1, y_trainset_res_ST1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_parameters ={ 'n_estimators': [100,200,300,400,500],'criterion': ['entropy', 'gini'], 'max_depth': np.arange(3, 21)},{'min_samples_leaf': [5, 10, 20, 50, 100]}\n",
    "RF_GS = GridSearchCV(estimator=RF,param_grid=RF_parameters, cv= 3,scoring=\"accuracy\")\n",
    "RF_GS.fit(X_trainset,y_trainset)\n",
    "RF_GS_ST=RF_GS.fit(X_trainset_res_ST1, y_trainset_res_ST1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_2_GS= RF_GS.predict(X_testset)\n",
    "yhat_prob_2_GS=RF_GS.predict_proba(X_testset)\n",
    "RF_Acc_GS=round(metrics.accuracy_score(y_testset, yhat_2_GS),4)\n",
    "#RF_Jcc_GS=round(jaccard_similarity_score(y_testset, yhat_2_GS),4)\n",
    "#RF_lgl_GS=round(log_loss(y_testset, yhat_prob_2_GS),4)\n",
    "RF_F1_GS=round(f1_score(y_testset, yhat_2_GS, average='weighted'),4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_2_GS_ST= DT_GS_ST.predict(X_testset)\n",
    "yhat_prob_2_GS=DT_GS.predict_proba(X_testset)\n",
    "RF_Acc_GS_ST=round(metrics.accuracy_score(y_testset, yhat_2_GS_ST),4)\n",
    "#RF_Jcc_GS_ST=round(jaccard_similarity_score(y_testset, yhat_2_GS_ST),4)\n",
    "#DT_lgl_GS=round(log_loss(y_testset, yhat_prob_1_GS_ST),4)\n",
    "RF_F1_GS_ST=round(f1_score(y_testset, yhat_2_GS_ST, average='weighted'),4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_RF = {'índices de rendimiento':['Accuracy','F1-Score'],\n",
    "             'Bosque de decisión':[RF_Acc,RF_F1],\n",
    "             'Grid Search':[RF_Acc_GS,RF_F1_GS],\n",
    "                'GS+SMOTE-Tomek':[RF_Acc_GS_ST,RF_F1_GS_ST]}\n",
    "Tabla_resultados_RF=pd.DataFrame(resultados_RF)\n",
    "print(Tabla_resultados_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "ex = shap.TreeExplainer(RF)\n",
    "shap_values = ex.shap_values(X)\n",
    "shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresión logística (multi-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LR = LogisticRegression(C=0.01, solver='newton-cg',penalty='l2',multi_class='ovr').fit(X_trainset,y_trainset)\n",
    "yhat_3= LR.predict(X_testset)\n",
    "yhat_prob_3=LR.predict_proba(X_testset)\n",
    "LR_Acc=round(metrics.accuracy_score(y_testset, yhat_3),4)\n",
    "#LR_Jcc=round(jaccard_similarity_score(y_testset, yhat_3),4)\n",
    "LR_lgl=round(log_loss(y_testset, yhat_prob_3),4)\n",
    "LR_F1=f1_score(y_testset, yhat_3, average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_GS = LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "LR_GS.fit(X_trainset,y_trainset)\n",
    "LR_GS_ST=LR_GS.fit(X_trainset_res_ST1, y_trainset_res_ST1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_parameters ={'C':(0.1,1,10), 'penalty':['l1','l2','elasticnet']}\n",
    "LR_GS = GridSearchCV(estimator=LR,param_grid=LR_parameters, verbose=True, n_jobs=-1,cv=3)\n",
    "LR_GS.fit(X_trainset,y_trainset)\n",
    "LR_GS_ST=LR_GS.fit(X_trainset_res_ST1, y_trainset_res_ST1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_3_GS= LR_GS.predict(X_testset)\n",
    "yhat_prob_3_GS=LR_GS.predict_proba(X_testset)\n",
    "LR_Acc_GS=round(metrics.accuracy_score(y_testset, yhat_3_GS),4)\n",
    "#LR_Jcc_GS=round(jaccard_similarity_score(y_testset, yhat_3_GS),4)\n",
    "LR_lgl_GS=round(log_loss(y_testset, yhat_prob_3_GS),4)\n",
    "LR_F1_GS=round(f1_score(y_testset, yhat_3_GS, average='weighted'),4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_3_GS= LR_GS.predict(X_testset)\n",
    "yhat_prob_3_GS=LR_GS.predict_proba(X_testset)\n",
    "LR_Acc_GS=round(metrics.accuracy_score(y_testset, yhat_3_GS),4)\n",
    "#LR_Jcc_GS=round(jaccard_similarity_score(y_testset, yhat_3_GS),4)\n",
    "LR_lgl_GS=round(log_loss(y_testset, yhat_prob_3_GS),4)\n",
    "LR_F1_GS=round(f1_score(y_testset, yhat_3_GS, average='weighted'),4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_3_GS_ST= LR_GS_ST.predict(X_testset)\n",
    "#yhat_prob_2_GS=DT_GS.predict_proba(X_testset)\n",
    "LR_Acc_GS_ST=round(metrics.accuracy_score(y_testset, yhat_3_GS_ST),4)\n",
    "#LR_Jcc_GS_ST=round(jaccard_similarity_score(y_testset, yhat_3_GS_ST),4)\n",
    "#DT_lgl_GS=round(log_loss(y_testset, yhat_prob_1_GS_ST),4)\n",
    "LR_F1_GS_ST=round(f1_score(y_testset, yhat_3_GS_ST, average='weighted'),4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_LR = {'índices de rendimiento':['Accuracy','F1-Score'],\n",
    "             'Regresión Logística':[LR_Acc,LR_F1],\n",
    "             'Grid Search':[LR_Acc_GS,LR_F1_GS],\n",
    "                 'GS+SMOTE-Tomek':[LR_Acc_GS_ST,LR_F1_GS_ST]}\n",
    "Tabla_resultados_LR=pd.DataFrame(resultados_LR)\n",
    "print(Tabla_resultados_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kerner Explainer\n",
    "explainer = shap.KernelExplainer(LR.predict_proba,X[:100])\n",
    "shap_values = explainer.shap_values(X[:100])\n",
    "shap.summary_plot(shap_values, X[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "NN = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1).fit(X_trainset,y_trainset)\n",
    "yhat_4 = NN.predict(X_testset)\n",
    "yhat_prob_4=NN.predict_proba(X_testset)\n",
    "NN_Acc=round(metrics.accuracy_score(y_testset, yhat_4),4)\n",
    "#NN_Jcc=round(jaccard_similarity_score(y_testset, yhat_3),4)\n",
    "NN_lgl=round(log_loss(y_testset, yhat_prob_4),4)\n",
    "NN_F1=f1_score(y_testset, yhat_4, average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_GS = MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "              hidden_layer_sizes=(50, 100, 50), learning_rate='constant',\n",
    "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
    "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
    "              power_t=0.5, random_state=1, shuffle=True, solver='adam',\n",
    "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "              warm_start=False)\n",
    "NN_GS.fit(X_trainset,y_trainset)\n",
    "NN_GS_ST=NN_GS.fit(X_trainset_res_ST1, y_trainset_res_ST1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_parameters = {'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],'alpha': [0.0001, 0.05],'learning_rate': ['constant','adaptive']}\n",
    "\n",
    "NN_GS = GridSearchCV(estimator=NN,param_grid=NN_parameters, cv= 3, verbose=True,scoring=\"accuracy\")\n",
    "NN_GS.fit(X_trainset,y_trainset)\n",
    "NN_GS_ST=NN_GS.fit(X_trainset_res_ST1, y_trainset_res_ST1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_4_GS= NN_GS.predict(X_testset)\n",
    "#yhat_prob_4_GS=NN_GS.predict_proba(X_testset)\n",
    "NN_Acc_GS=round(metrics.accuracy_score(y_testset, yhat_4_GS),4)\n",
    "#NN_Jcc_GS=round(jaccard_similarity_score(y_testset, yhat_4_GS),4)\n",
    "#NN_lgl_GS=round(log_loss(y_testset, yhat_prob_4_GS),4)\n",
    "NN_F1_GS=round(f1_score(y_testset, yhat_4_GS, average='weighted'),4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_4_GS_ST= NN_GS_ST.predict(X_testset)\n",
    "#yhat_prob_2_GS=DT_GS.predict_proba(X_testset)\n",
    "NN_Acc_GS_ST=round(metrics.accuracy_score(y_testset, yhat_4_GS_ST),4)\n",
    "#NN_Jcc_GS_ST=round(jaccard_similarity_score(y_testset, yhat_4_GS_ST),4)\n",
    "#DT_lgl_GS=round(log_loss(y_testset, yhat_prob_1_GS_ST),4)\n",
    "NN_F1_GS_ST=round(f1_score(y_testset, yhat_4_GS_ST, average='weighted'),4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_NN = {'índices de rendimiento':['Accuracy','F1-Score'],\n",
    "             'Red Neuronal':[NN_Acc,NN_F1],\n",
    "             'Grid Search':[NN_Acc_GS,NN_F1_GS],\n",
    "                'GS+SMOTE-Tomek':[NN_Acc_GS_ST,NN_F1_GS_ST]}\n",
    "Tabla_resultados_NN=pd.DataFrame(resultados_NN)\n",
    "print(Tabla_resultados_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_DF=pd.DataFrame(X, columns=df_hosp.columns)\n",
    "data_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "perm = PermutationImportance(NN, random_state=1).fit(data_DF, y)\n",
    "eli5.show_weights(perm, feature_names =data_DF.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kerner Explainer\n",
    "import shap\n",
    "explainer = shap.KernelExplainer(NN.predict_proba,data_DF[:100])\n",
    "shap_values = explainer.shap_values(data_DF[:100])\n",
    "shap.summary_plot(shap_values, data_DF[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "SVM = svm.SVC(kernel='rbf',decision_function_shape='ovo', probability=True)\n",
    "SVM.fit(X_trainset, y_trainset) \n",
    "yhat_5 = SVM.predict(X_testset)\n",
    "yhat_prob_5=SVM.predict_proba(X_testset)\n",
    "SVM_Acc=round(metrics.accuracy_score(y_testset, yhat_5),4)\n",
    "#SVM_Jcc=round(jaccard_similarity_score(y_testset, yhat_5),4)\n",
    "SVM_lgl=round(log_loss(y_testset, yhat_prob_5),4)\n",
    "SVM_F1=f1_score(y_testset, yhat_5, average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_parameters ={'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "SVM_GS = GridSearchCV(estimator=SVM,param_grid=SVM_parameters, cv= 3, verbose=True, n_jobs=-1)\n",
    "SVM_GS.fit(X_trainset,y_trainset)\n",
    "SVM_GS_ST=SVM_GS.fit(X_trainset_res_ST1, y_trainset_res_ST1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_5_GS= SVM_GS.predict(X_testset)\n",
    "yhat_prob_5_GS=SVM_GS.predict_proba(X_testset)\n",
    "SVM_Acc_GS=round(metrics.accuracy_score(y_testset, yhat_5_GS),4)\n",
    "#SVM_Jcc_GS=round(jaccard_similarity_score(y_testset, yhat_5_GS),4)\n",
    "SVM_lgl_GS=round(log_loss(y_testset, yhat_prob_5_GS),4)\n",
    "SVM_F1_GS=round(f1_score(y_testset, yhat_5_GS, average='weighted'),4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_5_GS_ST= NN_GS_ST.predict(X_testset)\n",
    "#yhat_prob_2_GS=DT_GS.predict_proba(X_testset)\n",
    "SVM_Acc_GS_ST=round(metrics.accuracy_score(y_testset, yhat_5_GS_ST),4)\n",
    "SVM_Jcc_GS_ST=round(jaccard_similarity_score(y_testset, yhat_5_GS_ST),4)\n",
    "#DT_lgl_GS=round(log_loss(y_testset, yhat_prob_1_GS_ST),4)\n",
    "SVM_F1_GS_ST=round(f1_score(y_testset, yhat_5_GS_ST, average='weighted'),4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_SVM = {'índices de rendimiento':['Accuracy','Jaccard','F1-Score'],\n",
    "             'Red Neuronal':[SVM_Acc,SVM_Jcc,SVM_F1],\n",
    "             'Grid Search':[SVM_Acc_GS,SVM_Jcc_GS,SVM_F1_GS],\n",
    "             'GS+SMOTE-Tomek':[SVM_Acc_GS_ST,SVM_Jcc_GS_ST,SVM_F1_GS_ST]}\n",
    "Tabla_resultados_SVM=pd.DataFrame(resultados_SVM)\n",
    "print(Tabla_resultados_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kerner Explainer\n",
    "explainer = shap.KernelExplainer(SVM.predict_proba,X[:100])\n",
    "shap_values = explainer.shap_values(X[:100])\n",
    "shap.summary_plot(shap_values, X[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = {'Algoritmos de clasificación':['Árboles de decisión','AD+GS','Bosques de decisión','BD+GS','Regresión Logística','RL+GS','Red Neuronal','RN+GS'],\n",
    "             'Accuracy':[DT_Acc,DT_Acc_GS,RF_Acc,RF_Acc_GS,LR_Acc,LR_Acc_GS,NN_Acc,NN_Acc_GS],\n",
    "                     'F1-Score':[DT_F1,DT_F1_GS,RF_F1,RF_F1_GS,LR_F1,LR_F1_GS,NN_F1,NN_F1_GS]}\n",
    "Tabla_resultados=pd.DataFrame(resultados)\n",
    "print(Tabla_resultados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1 id=\"Matrices de confusión\">Matrices de confusión</h1>\n",
    "<p>\n",
    "En esta sección se construyen matrices de confusión para evaluar la eficacia de cada algoritmo\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Matriz de confusión',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    Esta función muestra y dibuja la matriz de confusión.\n",
    "    La normalización se puede aplicar estableciendo el valor `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Matriz de confusión normalizada\")\n",
    "    else:\n",
    "        print('Matriz de confusión sin normalización')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Etiqueta Real')\n",
    "    plt.xlabel('Etiqueta Predicha')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_testset, yhat_1, labels=['A.P.S','DOMICILIO','HOSPITALIZAR','OTRO','OTRO ESTABLECIMIENTO'])\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['A.P.S','DOMICILIO','HOSPITALIZAR','OTRO','OTRO ESTABLECIMIENTO'],normalize= False,  title='Matriz de confusión árbol de decisión')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bosque de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_testset, yhat_2_GS_ST, labels=['A.P.S','DOMICILIO','HOSPITALIZAR','OTRO','OTRO ESTABLECIMIENTO'])\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['A.P.S','DOMICILIO','HOSPITALIZAR','OTRO','OTRO ESTABLECIMIENTO'],normalize= False,  title='Matriz de confusión bosque de decisión + ST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_testset, yhat_3_GS_ST, labels=['A.P.S','DOMICILIO','HOSPITALIZAR','OTRO','OTRO ESTABLECIMIENTO'])\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['A.P.S','DOMICILIO','HOSPITALIZAR','OTRO','OTRO ESTABLECIMIENTO'],normalize= False,  title='Matriz de confusión regresión logística +ST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_testset, yhat_4_GS_ST, labels=['A.P.S','DOMICILIO','HOSPITALIZAR','OTRO','OTRO ESTABLECIMIENTO'])\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['A.P.S','DOMICILIO','HOSPITALIZAR','OTRO','OTRO ESTABLECIMIENTO'],normalize= False,  title='Matriz de confusión red neuronal +ST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_testset, yhat_5, labels=['A.P.S','DOMICILIO','HOSPITALIZAR','OTRO','OTRO ESTABLECIMIENTO'])\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['A.P.S','DOMICILIO','HOSPITALIZAR','OTRO','OTRO ESTABLECIMIENTO'],normalize= False,  title='Matriz de confusión SVM')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center><font size = 5>Machine Learning models for aiding the decision-making process in emergency departments</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Tabla comparativa de algoritmos<h1>\n",
    "<h3>Descripción</h3>\n",
    "<p>\n",
    "En este script se desarrollará una serie de predicciones basadas en datos del hospital San Juan de Dios Curicó, correspondientes al año 2018 representados por registros de urgencias. El objetivo es predecir, mediante un conjunto de algoritmos, la necesidad de hospitalización de un paciente de urgencias,tomando como input, datos proporcionados por el paciente en la etapa de registro, sus signos vitales registrados en la etapa de triage y el diagnóstico ofrecido por el médico tratante.\n",
    "Se correrán algoritmos de prodicción tales como árboles y bosques de desición, regresión logística, support vector machines y redes neuronales. Para finalmente evaluar el rendimiento de cada algoritmo en términos de la predicción, mediante indicadores tales como Acuraccy, F1-Score, Curva ROC, Índice de Jaccard y logloss\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Descripción de datos\">Descripción de datos</h1>\n",
    "<p>\n",
    "Los datos utilizados fueros proporcionados por el Hospital San Juan de Dios, Curicó, Chile y corresponden a 4.971 registros de pacientes que asistieron a urgencias durante el periodo comprendido entre el 1 de enero de 2018 y agosto de 2019, los datos fueron limpiados y transformados en un script desarrollado previamente\n",
    "<ul>\n",
    "    <li>Datos: <a href=\"https://drive.google.com/open?id=1Bp7_MnK6cGwgBuwIq1a8S4DS_0wVDiAD\" target=\"_blank\">https://drive.google.com/open?id=1Bp7_MnK6cGwgBuwIq1a8S4DS_0wVDiAD</a></li>\n",
    "    <li>Tipo de datos: csv</li>\n",
    "   </ul>\n",
    "<p>\n",
    "Las variables presentes en los datos se describen a continuación:\n",
    "<ul>    \n",
    "   \n",
    "   <li><b>PAC_EDAD</b>: corresponde a la edad del paciente en enteros</li>\n",
    "   <li><b>MOTIVO_CONSULTA</b>: corresponde a la razón por la que el paciente acude al servicio de urgencias string</li>\n",
    "   <li><b>MEDIO</b>: corresponde al medio de llegada, mediante el que el paciente acude al servicio de urgencias</li>\n",
    "   <li><b>SEXO</b>: corresponde al sexo del paciente</li>\n",
    "   <li><b>CAT</b>: corresponde a la categoría de gravedad asignada al paciente en el proceso de Triage</li>\n",
    "   <li><b>PRESION_SIST</b>: corresponde la presión sistólica del paciente </li>\n",
    "   <li><b>PRESION_DIAST</b>: corresponde la presióndiastólica del paciente</li>\n",
    "   <li><b>SATO2</b>: Dato numérico que representa la saturometria del paciente (Nivel de oxigeno en la sangre)</li>\n",
    "   <li><b>TEMPERATURA</b>: corresponde a la temperatura corporal del paciente en el momento de la categorización</li>\n",
    "   <li><b>GLASGOW</b>: corresponde a al nivel registrado por el paciente en la escala Glasgow</li>\n",
    "   <li><b>DM</b>: corresponde si el paciente presenta o no Diabetes Mellitus</li>\n",
    "   <li><b>EVA</b>: corresponde si se aplica al paciente una evaluación de vias aéreas</li>\n",
    "   <li><b>HGT</b>: corresponde a la medida de azucar en la sangre del paciente</li>\n",
    "   <li><b>LCFA</b>: corresponde a si el paciente presenta obstrucción crónica de vías aéreas</li>\n",
    "   <li><b>FR</b>: corresponde a la frecuencia respiratoria del paciente</li>\n",
    "   <li><b>HTA</b>: corresponde a si el paciente posee Hipertención Arterial</li>\n",
    "   <li><b>HORA_INSC</b>: corresponde a la hora en la que el paciente fue categorizado</li>\n",
    "   <li><b>MIN_INSC</b>: corresponde al minuto en que el paciente fue categorizado</li>\n",
    "   <li><b>TIEMPO_ESPERA_CAT</b>: corresponde al tiempo que espera el paciente luego de ser registrado, para ser categorizado</li>\n",
    "      \n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "import sklearn as sk  \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import f1_score\n",
    "#Métodos de tuneo de parámetros\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo= 'df_limpia_hosp.csv'\n",
    "df_urg= pd.read_csv(archivo,encoding='latin-1',sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PAC_EDAD', 'COMUNA', 'PREVISION', 'MOTIVO_CONSULTA',\n",
       "       'MEDIO', 'DESC_EVENTO', 'SEXO', 'SATO2', 'TEMPERATURA', 'GLASGOW', 'DM',\n",
       "       'EVA', 'HGT', 'LCFA', 'FR', 'HTA', 'CAT', 'DESTINO', 'VIOLENCIA',\n",
       "       'TIEMPO_ESPERA_CAT', 'TIEMPO_ESPERA_ATENCION', 'DURACION_ATENCION',\n",
       "       'MES_INSC', 'SEMANA_INSC', 'DIA_MES_INSC', 'DIA_SEMANA_INSC',\n",
       "       'HORA_INSC', 'MIN_INSC', 'DIA_MES_FIN_ATENCION',\n",
       "       'DIA_SEMANA_FIN_ATENCION', 'HORA_INSC_FIN_ATENCION',\n",
       "       'MIN_INSC_FIN_ATENCION', 'PRESION_SIST', 'PRESION_DIAST'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_urg.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionar las variables relevantes para la predicción y asignarselas a la matriz X, de variables independientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hosp = df_urg[[\"PAC_EDAD\",'MOTIVO_CONSULTA','MEDIO', 'SEXO','DESC_EVENTO','GLASGOW', 'DM', 'EVA','HGT', 'LCFA', 'FR', \n",
    "                 'HTA','CAT','TIEMPO_ESPERA_CAT','MES_INSC','DIA_MES_INSC','SEMANA_INSC','DIA_SEMANA_INSC','HORA_INSC',\n",
    "                 'MIN_INSC','PRESION_SIST','PRESION_DIAST','TIEMPO_ESPERA_CAT','TIEMPO_ESPERA_ATENCION','DURACION_ATENCION','DESTINO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_hosp[[\"PAC_EDAD\",'MOTIVO_CONSULTA','MEDIO', 'SEXO','GLASGOW', 'DM', 'EVA','HGT', 'LCFA', 'FR', \n",
    "                 'HTA','CAT','TIEMPO_ESPERA_CAT','MES_INSC','DIA_MES_INSC','SEMANA_INSC','DIA_SEMANA_INSC','HORA_INSC',\n",
    "                 'MIN_INSC','PRESION_SIST','PRESION_DIAST','TIEMPO_ESPERA_CAT','TIEMPO_ESPERA_ATENCION','DURACION_ATENCION']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[79, 'OTROS, ESPECIFICAR', 'POR SUS PROPIOS MEDIOS', 'FEMENINO',\n",
       "        15.0, 'S', 3.0, 121.0, 'S', 14.0, 'S', 'C3', 11, 11, 5, 23, 21,\n",
       "        2, 17, 1, 159.0, 64.0, 11, 11, 93, 268],\n",
       "       [36, 'OTROS, ESPECIFICAR', 'SAMU MOVIL AVANZADO', 'MASCULINO',\n",
       "        15.0, 'N', 5.0, 114.0, 'N', 17.0, 'N', 'C3', 3, 3, 5, 17, 20, 3,\n",
       "        22, 18, 131.0, 84.0, 3, 3, 14, 209]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1 id=\"Preprocesamiento de datos\">Preprocesamiento de datos</h1>\n",
    "<p>\n",
    "Para aplicar el paquete de arboles de desición, los datos deben ser numéricos, en este caso siguen siendo en su mayoría categoricos pero serán transformados a nominales.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesando motivo de consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_motivo_consulta = preprocessing.LabelEncoder()\n",
    "le_motivo_consulta.fit(['OTROS, ESPECIFICAR','DOLOR Y/O MOLESTIAS ABDOMEN'\n",
    ",'PROBLEMAS RESPIRATORIOS','DOLOR Y/O MOLESTIAS TORAX','DOLOR Y/O MOLESTIAS EXTREMIDADES',\n",
    "'ACCIDENTE/TRAUMATISMO OTRO TIPO','ACCIDENTE/TRAUMATISMO EN EL HOGAR', \n",
    "'DIABETES MELLITUS DESCOMPENSADA','VOMITOS',\n",
    "'DOLOR Y/O MOLESTIAS CABEZA Y CUELLO','PRESION ARTERIAL ELEVADA',\n",
    "'ACCIDENTE/TRAUMATISMO VIA PUBLICA','FIEBRE','CONVULSIONES',\n",
    "'CONSTATACION DE LESIONES',\n",
    "'ALCOHOLEMIA + CONST.LESIONES','DIARREA','AGRESION Y/O VIOLENCIA',\n",
    "'MORDEDURA ANIMAL','MORDEDURA ARAÃA','QUEMADURAS','PROCEDIMIENTO DE HEMODINAMIA',\n",
    "'ALCOHOLEMIA','HERIDAS Y/O HEMORRAGIA' ])\n",
    "\n",
    "X[:,1] = le_motivo_consulta.transform(X[:,1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[79, 18, 'POR SUS PROPIOS MEDIOS', ..., 11, 93, 268],\n",
       "       [36, 18, 'SAMU MOVIL AVANZADO', ..., 3, 14, 209],\n",
       "       [37, 18, 'POR SUS PROPIOS MEDIOS', ..., 2, 11, 10],\n",
       "       ...,\n",
       "       [55, 18, 'AMBULANCIA APS', ..., 5, 68, 2],\n",
       "       [76, 18, 'SAMU MOVIL AVANZADO', ..., 3, 6, 713],\n",
       "       [64, 18, 'POR SUS PROPIOS MEDIOS', ..., 13, 45, 11]], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesando medio de llegada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_medio = preprocessing.LabelEncoder()\n",
    "le_medio.fit([ 'POR SUS PROPIOS MEDIOS','SAMU MOVIL AVANZADO',\n",
    "'AMBULANCIA APS','AMBULANCIA HOSPITAL','SAMU MOVIL BASICO',\n",
    "'VEHICULO POLICIAL CARABINEROS','OTRO MEDIO TERRESTRE PAGADO',\n",
    "'GENDARMERIA','AMBULANCIA CLINICAS PRIVADAS'])\n",
    "X[:,2] = le_medio.transform(X[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamiento Sexo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_sexo = preprocessing.LabelEncoder()\n",
    "le_sexo.fit([ 'FEMENINO','MASCULINO'])\n",
    "X[:,3] = le_sexo.transform(X[:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamiento DM (Diabetes Mellitus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_DM = preprocessing.LabelEncoder()\n",
    "le_DM.fit([ 'S', 'N','D'])\n",
    "X[:,5] = le_DM.transform(X[:,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamiento LCFA (Limintación crónica del flujo aéreo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_LCFA = preprocessing.LabelEncoder()\n",
    "le_LCFA.fit([ 'S', 'N','D'])\n",
    "X[:,8] = le_LCFA.transform(X[:,8]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamiento HTA (Hipertención Arterial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_HTA = preprocessing.LabelEncoder()\n",
    "le_HTA.fit([ 'S', 'N','D'])\n",
    "X[:,10] = le_HTA.transform(X[:,10]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamiento CAT ( Categoría)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_CAT = preprocessing.LabelEncoder()\n",
    "le_CAT.fit([ 'C1', 'C2','C3','C4','C5'])\n",
    "X[:,11] = le_CAT.transform(X[:,11]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asignación de la variable dependiente a predecir (categoría), al vector y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_hosp[\"DESTINO\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1 id=\"Normalización de datos\">Normalización de datos</h1>\n",
    "<p>\n",
    "Para aplicar el paquete de arboles de desición, los datos deben estar en una escala similar, es por ello que optamos por normalizarlos para que los valores estén en un rango entre -2 y 2. Esta medida no altera los resultados aunque si faborece a la eficiencia de los algoritmos\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99625445,  0.42786127,  0.36170022, -0.85208079,  0.2006122 ,\n",
       "         0.57425949, -0.64295632, -0.62778175,  3.3925378 , -1.01463125,\n",
       "         0.65766514,  0.49536096,  0.10775771,  0.10775771, -0.39384883,\n",
       "         0.84989103, -0.32068735, -0.46184096,  0.6603932 , -1.69078044,\n",
       "         0.64321137, -1.02713707,  0.10775771,  0.10775771,  0.79010273,\n",
       "         0.26093814],\n",
       "       [-1.6282834 ,  0.42786127,  0.87119634,  1.17359764,  0.2006122 ,\n",
       "        -1.54342888,  0.44213479, -0.70181777, -0.20863781, -0.14306879,\n",
       "        -1.39202352,  0.49536096, -0.0672743 , -0.0672743 , -0.39384883,\n",
       "         0.16082017, -0.39319425,  0.04833935,  1.53679199, -0.6976216 ,\n",
       "        -0.34677353,  0.13840688, -0.0672743 , -0.0672743 , -0.55515844,\n",
       "        -0.03713735],\n",
       "       [-1.56724764,  0.42786127,  0.36170022,  1.17359764,  0.2006122 ,\n",
       "         0.57425949, -0.64295632, -0.41625025, -0.20863781, -0.43358961,\n",
       "        -1.39202352, -1.70128431, -0.0891533 , -0.0891533 , -0.39384883,\n",
       "        -0.41340556, -0.46570116,  1.06869998, -0.56656511,  0.58764278,\n",
       "        -0.27606032, -1.02713707, -0.0891533 , -0.0891533 , -0.6062443 ,\n",
       "        -1.04251062],\n",
       "       [ 0.99625445, -0.68267464,  0.36170022, -0.85208079,  0.2006122 ,\n",
       "        -1.54342888, -0.64295632, -0.3950971 , -0.20863781, -0.72411043,\n",
       "         0.65766514,  0.49536096, -0.0453953 , -0.0453953 , -1.3378327 ,\n",
       "        -0.5282507 , -1.40829092,  1.57888029,  0.83567296, -0.63920049,\n",
       "        -1.0539056 ,  0.02185248, -0.0453953 , -0.0453953 , -0.31675772,\n",
       "        -0.41099475],\n",
       "       [ 0.38589681, -0.68267464,  0.36170022, -0.85208079,  0.2006122 ,\n",
       "         0.57425949, -0.10041077, -0.46913312, -0.20863781, -0.72411043,\n",
       "         0.65766514,  0.49536096,  0.34842673,  0.34842673, -0.07918754,\n",
       "        -0.06887012, -0.10316663,  0.55851967,  0.48511344,  1.4639594 ,\n",
       "        -1.86710749, -1.20196866,  0.34842673,  0.34842673,  1.16473242,\n",
       "        -0.52214154]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1 id=\"Análisis de componentes principales\">Análisis de componentes principales</h1>\n",
    "<p>\n",
    "Se realizó el análisis de componentes principales con el fin de reducir la dimensionalidad de la base de datos utilizada para la predicción de categoría. El objetivo de reducir la dimensionalidad de la base de datos es agilizar los procesos de entrenamiento y predicción de la categoria de pacientes, además de identificar las variables que presentan una mayor utilidad para esta, descartando las que no aportan indormación a la predicción.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Make an instance of the Model\n",
    "pca = PCA(.95)\n",
    "pca.fit(X)\n",
    "pca.explained_variance_ratio_\n",
    "X.shape\n",
    "#pca.n_components_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1 id=\"Configurando algoritmos\">Configurando algoritmos</h1>\n",
    "<p>\n",
    "En esta sección se definen parámetros necesarios para la correcta aplicación de los algoritmos a implementar, además de seccionar el conjunto de datos en datos de prueba(30%)y de entrenamiento (70%). Los parámetros escogidos pueden ser modificados con el fin de obtener resultados diferentes\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentación del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Árbol de desición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT= DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n",
    "DT.fit(X_trainset,y_trainset)\n",
    "yhat_1 = DT.predict(X_testset)\n",
    "yhat_prob_1=DT.predict_proba(X_testset)\n",
    "DT_Acc=round(metrics.accuracy_score(y_testset, yhat_1),4)\n",
    "DT_Jcc=round(jaccard_similarity_score(y_testset, yhat_1),4)\n",
    "DT_lgl=round(log_loss(y_testset, yhat_prob_1),4)\n",
    "DT_F1=f1_score(y_testset, yhat_1, average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 46 candidates, totalling 138 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 138 out of 138 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=42,\n",
       "                                              splitter='best'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'criterion': ['entropy', 'gini'],\n",
       "                          'max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20])},\n",
       "                         {'min_samples_leaf': [1, 5, 10, 20, 50, 100]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_parameters = [{'criterion': ['entropy', 'gini'], 'max_depth': np.arange(1, 21)},{'min_samples_leaf': [1, 5, 10, 20, 50, 100]}]\n",
    "DT_GS = GridSearchCV(DecisionTreeClassifier(random_state=42), DT_parameters, verbose=True, n_jobs=-1, cv=3)\n",
    "DT_GS.fit(X_trainset,y_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=100, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=42, splitter='best')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "yhat_1_GS= DT_GS.predict(X_testset)\n",
    "yhat_prob_1_GS=DT_GS.predict_proba(X_testset)\n",
    "DT_Acc_GS=round(metrics.accuracy_score(y_testset, yhat_1_GS),4)\n",
    "DT_Jcc_GS=round(jaccard_similarity_score(y_testset, yhat_1_GS),4)\n",
    "DT_lgl_GS=round(log_loss(y_testset, yhat_prob_1_GS),4)\n",
    "DT_F1_GS=round(f1_score(y_testset, yhat_1_GS, average='weighted'),4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  índices de rendimiento  Árboles de decisión  Grid Search\n",
      "0               Accuracy             0.405500       0.4001\n",
      "1                Jaccard             0.405500       0.4001\n",
      "2                LogLoss             1.636400       1.4113\n",
      "3               F1-Score             0.316703       0.3577\n"
     ]
    }
   ],
   "source": [
    "resultados_DT = {'índices de rendimiento':['Accuracy','Jaccard','LogLoss','F1-Score'],\n",
    "             'Árboles de decisión':[DT_Acc,DT_Jcc,DT_lgl,DT_F1],\n",
    "             'Grid Search':[DT_Acc_GS,DT_Jcc_GS,DT_lgl_GS,DT_F1_GS]}\n",
    "Tabla_resultados_DT=pd.DataFrame(resultados_DT)\n",
    "print(Tabla_resultados_DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bosque de desición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF= RandomForestClassifier(max_depth=2, random_state=0)\n",
    "RF.fit(X_trainset,y_trainset)\n",
    "yhat_2 = RF.predict(X_testset)\n",
    "yhat_prob_2=RF.predict_proba(X_testset)\n",
    "RF_Acc=round(metrics.accuracy_score(y_testset, yhat_2),4)\n",
    "RF_Jcc=round(jaccard_similarity_score(y_testset, yhat_2),4)\n",
    "RF_lgl=round(log_loss(y_testset, yhat_prob_2),4)\n",
    "RF_F1=f1_score(y_testset, yhat_2, average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=2,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=0,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [2, 3, 4, 5, 6, 7, 8],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [200, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_parameters ={ 'n_estimators': [200, 500],'max_features': ['auto', 'sqrt', 'log2'],'max_depth' : [2,3,4,5,6,7,8],'criterion' :['gini', 'entropy']}\n",
    "RF_GS = GridSearchCV(estimator=RF,param_grid=RF_parameters, verbose=True, n_jobs=-1,cv=3)\n",
    "RF_GS.fit(X_trainset,y_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=8, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "yhat_2_GS= RF_GS.predict(X_testset)\n",
    "yhat_prob_2_GS=RF_GS.predict_proba(X_testset)\n",
    "RF_Acc_GS=round(metrics.accuracy_score(y_testset, yhat_2_GS),4)\n",
    "RF_Jcc_GS=round(jaccard_similarity_score(y_testset, yhat_2_GS),4)\n",
    "RF_lgl_GS=round(log_loss(y_testset, yhat_prob_2_GS),4)\n",
    "RF_F1_GS=round(f1_score(y_testset, yhat_2_GS, average='weighted'),4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  índices de rendimiento  Bosque de decisión  Grid Search\n",
      "0               Accuracy             0.37600       0.4216\n",
      "1                Jaccard             0.37600       0.4216\n",
      "2                LogLoss             1.29570       1.2584\n",
      "3               F1-Score             0.27888       0.3761\n"
     ]
    }
   ],
   "source": [
    "resultados_RF = {'índices de rendimiento':['Accuracy','Jaccard','LogLoss','F1-Score'],\n",
    "             'Bosque de decisión':[RF_Acc,RF_Jcc,RF_lgl,RF_F1],\n",
    "             'Grid Search':[RF_Acc_GS,RF_Jcc_GS,RF_lgl_GS,RF_F1_GS]}\n",
    "Tabla_resultados_RF=pd.DataFrame(resultados_RF)\n",
    "print(Tabla_resultados_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresión logística (multi-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LR = LogisticRegression(C=0.01, solver='newton-cg',penalty='l2',multi_class='ovr').fit(X_trainset,y_trainset)\n",
    "yhat_3= LR.predict(X_testset)\n",
    "yhat_prob_3=LR.predict_proba(X_testset)\n",
    "LR_Acc=round(metrics.accuracy_score(y_testset, yhat_3),4)\n",
    "LR_Jcc=round(jaccard_similarity_score(y_testset, yhat_3),4)\n",
    "LR_lgl=round(log_loss(y_testset, yhat_prob_3),4)\n",
    "LR_F1=f1_score(y_testset, yhat_3, average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=LogisticRegression(C=0.01, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='ovr',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='newton-cg',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_parameters ={'C':np.logspace(-3,3,7), 'penalty':['l1','l2']}\n",
    "LR_GS = GridSearchCV(estimator=LR,param_grid=LR_parameters, verbose=True, n_jobs=-1,cv=3)\n",
    "LR_GS.fit(X_trainset,y_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "yhat_3_GS= LR_GS.predict(X_testset)\n",
    "yhat_prob_3_GS=LR_GS.predict_proba(X_testset)\n",
    "LR_Acc_GS=round(metrics.accuracy_score(y_testset, yhat_3_GS),4)\n",
    "LR_Jcc_GS=round(jaccard_similarity_score(y_testset, yhat_3_GS),4)\n",
    "LR_lgl_GS=round(log_loss(y_testset, yhat_prob_3_GS),4)\n",
    "LR_F1_GS=round(f1_score(y_testset, yhat_3_GS, average='weighted'),4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  índices de rendimiento  Regresión Logística  Grid Search\n",
      "0               Accuracy             0.402100       0.4028\n",
      "1                Jaccard             0.402100       0.4028\n",
      "2                LogLoss             1.281000       1.2826\n",
      "3               F1-Score             0.353874       0.3626\n"
     ]
    }
   ],
   "source": [
    "resultados_LR = {'índices de rendimiento':['Accuracy','Jaccard','LogLoss','F1-Score'],\n",
    "             'Regresión Logística':[LR_Acc,LR_Jcc,LR_lgl,LR_F1],\n",
    "             'Grid Search':[LR_Acc_GS,LR_Jcc_GS,LR_lgl_GS,LR_F1_GS]}\n",
    "Tabla_resultados_LR=pd.DataFrame(resultados_LR)\n",
    "print(Tabla_resultados_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "NN = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1).fit(X_trainset,y_trainset)\n",
    "yhat_4 = NN.predict(X_testset)\n",
    "yhat_prob_4=NN.predict_proba(X_testset)\n",
    "NN_Acc=round(metrics.accuracy_score(y_testset, yhat_4),4)\n",
    "NN_Jcc=round(jaccard_similarity_score(y_testset, yhat_3),4)\n",
    "NN_lgl=round(log_loss(y_testset, yhat_prob_3),4)\n",
    "NN_F1=f1_score(y_testset, yhat_4, average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1260 candidates, totalling 3780 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 17.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 24.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 33.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 43.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3780 out of 3780 | elapsed: 51.9min finished\n",
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=MLPClassifier(activation='relu', alpha=1e-05,\n",
       "                                     batch_size='auto', beta_1=0.9,\n",
       "                                     beta_2=0.999, early_stopping=False,\n",
       "                                     epsilon=1e-08, hidden_layer_sizes=(5, 2),\n",
       "                                     learning_rate='constant',\n",
       "                                     learning_rate_init=0.001, max_fun=15000,\n",
       "                                     max_iter=200, momentum=0.9,\n",
       "                                     n_iter_no_change=10,\n",
       "                                     nesterovs_momentum=True, power_t=0.5,\n",
       "                                     random_state=1...\n",
       "                                     validation_fraction=0.1, verbose=False,\n",
       "                                     warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'alpha': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06]),\n",
       "                         'hidden_layer_sizes': array([ 5,  6,  7,  8,  9, 10, 11]),\n",
       "                         'max_iter': [500, 1000, 1500],\n",
       "                         'random_state': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         'solver': ['lbfgs']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_parameters ={'solver': ['lbfgs'], 'max_iter': [500,1000,1500], 'alpha': 10.0 ** -np.arange(1, 7), 'hidden_layer_sizes':np.arange(5, 12), 'random_state':[0,1,2,3,4,5,6,7,8,9]}\n",
    "NN_GS = GridSearchCV(estimator=NN,param_grid=NN_parameters, cv= 3, verbose=True, n_jobs=-1)\n",
    "NN_GS.fit(X_trainset,y_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=6, learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=8, shuffle=True, solver='lbfgs',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "yhat_4_GS= NN_GS.predict(X_testset)\n",
    "yhat_prob_4_GS=NN_GS.predict_proba(X_testset)\n",
    "NN_Acc_GS=round(metrics.accuracy_score(y_testset, yhat_4_GS),4)\n",
    "NN_Jcc_GS=round(jaccard_similarity_score(y_testset, yhat_4_GS),4)\n",
    "NN_lgl_GS=round(log_loss(y_testset, yhat_prob_4_GS),4)\n",
    "NN_F1_GS=round(f1_score(y_testset, yhat_4_GS, average='weighted'),4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  índices de rendimiento  Red Neuronal  Grid Search\n",
      "0               Accuracy      0.403500       0.3988\n",
      "1                Jaccard      0.402100       0.3988\n",
      "2                LogLoss      1.281000       1.3264\n",
      "3               F1-Score      0.310289       0.3472\n"
     ]
    }
   ],
   "source": [
    "resultados_NN = {'índices de rendimiento':['Accuracy','Jaccard','LogLoss','F1-Score'],\n",
    "             'Red Neuronal':[NN_Acc,NN_Jcc,NN_lgl,NN_F1],\n",
    "             'Grid Search':[NN_Acc_GS,NN_Jcc_GS,NN_lgl_GS,NN_F1_GS]}\n",
    "Tabla_resultados_NN=pd.DataFrame(resultados_NN)\n",
    "print(Tabla_resultados_NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "SVM = svm.SVC(kernel='rbf',decision_function_shape='ovo', probability=True)\n",
    "SVM.fit(X_trainset, y_trainset) \n",
    "yhat_5 = SVM.predict(X_testset)\n",
    "yhat_prob_5=SVM.predict_proba(X_testset)\n",
    "SVM_Acc=round(metrics.accuracy_score(y_testset, yhat_5),4)\n",
    "SVM_Jcc=round(jaccard_similarity_score(y_testset, yhat_5),4)\n",
    "SVM_lgl=round(log_loss(y_testset, yhat_prob_5),4)\n",
    "SVM_F1=f1_score(y_testset, yhat_5, average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   54.1s\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovo', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=True, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001],\n",
       "                         'kernel': ['rbf', 'poly', 'sigmoid']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_parameters ={'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "SVM_GS = GridSearchCV(estimator=SVM,param_grid=SVM_parameters, cv= 3, verbose=True, n_jobs=-1)\n",
    "SVM_GS.fit(X_trainset,y_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovo', degree=3, gamma=0.01, kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "yhat_5_GS= SVM_GS.predict(X_testset)\n",
    "yhat_prob_5_GS=SVM_GS.predict_proba(X_testset)\n",
    "SVM_Acc_GS=round(metrics.accuracy_score(y_testset, yhat_5_GS),4)\n",
    "SVM_Jcc_GS=round(jaccard_similarity_score(y_testset, yhat_5_GS),4)\n",
    "SVM_lgl_GS=round(log_loss(y_testset, yhat_prob_5_GS),4)\n",
    "SVM_F1_GS=round(f1_score(y_testset, yhat_5_GS, average='weighted'),4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  índices de rendimiento  Red Neuronal  Grid Search\n",
      "0               Accuracy      0.404200       0.3981\n",
      "1                Jaccard      0.404200       0.3981\n",
      "2                LogLoss      1.286500       1.2847\n",
      "3               F1-Score      0.373516       0.3304\n"
     ]
    }
   ],
   "source": [
    "resultados_SVM = {'índices de rendimiento':['Accuracy','Jaccard','LogLoss','F1-Score'],\n",
    "             'Red Neuronal':[SVM_Acc,SVM_Jcc,SVM_lgl,SVM_F1],\n",
    "             'Grid Search':[SVM_Acc_GS,SVM_Jcc_GS,SVM_lgl_GS,SVM_F1_GS]}\n",
    "Tabla_resultados_SVM=pd.DataFrame(resultados_SVM)\n",
    "print(Tabla_resultados_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Algoritmos de clasificación  Accuracy  Jaccard  LogLoss  F1-Score\n",
      "0         Árboles de decisión    0.4001   0.4001   1.4113    0.3577\n",
      "1         Bosques de decisión    0.4216   0.4216   1.2584    0.3761\n",
      "2         Regresión Logística    0.4028   0.4028   1.2826    0.3626\n",
      "3                Red Neuronal    0.3988   0.3988   1.3264    0.3472\n",
      "4      Support Vector Machine    0.3981   0.3981   1.2847    0.3304\n"
     ]
    }
   ],
   "source": [
    "resultados = {'Algoritmos de clasificación':['Árboles de decisión','Bosques de decisión','Regresión Logística','Red Neuronal','Support Vector Machine'],\n",
    "             'Accuracy':[DT_Acc_GS,RF_Acc_GS,LR_Acc_GS,NN_Acc_GS,SVM_Acc_GS],\n",
    "             'Jaccard':[DT_Jcc_GS,RF_Jcc_GS,LR_Jcc_GS,NN_Jcc_GS,SVM_Jcc_GS],\n",
    "             'LogLoss':[DT_lgl_GS,RF_lgl_GS,LR_lgl_GS,NN_lgl_GS,SVM_lgl_GS],\n",
    "             'F1-Score':[DT_F1_GS,RF_F1_GS,LR_F1_GS,NN_F1_GS,SVM_F1_GS]}\n",
    "Tabla_resultados=pd.DataFrame(resultados)\n",
    "print(Tabla_resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1 id=\"Matrices de confusión\">Matrices de confusión</h1>\n",
    "<p>\n",
    "En esta sección se construyen matrices de confusión para evaluar la eficiaca de cada algoritmo\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Matriz de confusión',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    Esta función muestra y dibuja la matriz de confusión.\n",
    "    La normalización se puede aplicar estableciendo el valor `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Matriz de confusión normalizada\")\n",
    "    else:\n",
    "        print('Matriz de confusión sin normalización')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Etiqueta Real')\n",
    "    plt.xlabel('Etiqueta Predicha')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_testset, yhat_1, labels=['A.P.S','DOMICILIO','HOSPITALIZAR','OTRO','OTRO ESTABLECIMIENTO'])\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['A.P.S','DOMICILIO','HOSPITALIZAR','OTRO','OTRO ESTABLECIMIENTO'],normalize= False,  title='Matriz de confusión árbol de decisión')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bosque de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_testset, yhat_2, labels=['A.P.S','DOMICILIO','HOSPITALIZAR','OTRO','OTRO ESTABLECIMIENTO'])\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['A.P.S','DOMICILIO','HOSPITALIZAR','OTRO','OTRO ESTABLECIMIENTO'],normalize= False,  title='Matriz de confusión bosque de decisión')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_testset, yhat_3, labels=['A.P.S','DOMICILIO','HOSPITALIZAR','OTRO','OTRO ESTABLECIMIENTO'])\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['A.P.S','DOMICILIO','HOSPITALIZAR','OTRO','OTRO ESTABLECIMIENTO'],normalize= False,  title='Matriz de confusión regresión logística')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_testset, yhat_4, labels=['A.P.S','DOMICILIO','HOSPITALIZAR','OTRO','OTRO ESTABLECIMIENTO'])\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['A.P.S','DOMICILIO','HOSPITALIZAR','OTRO','OTRO ESTABLECIMIENTO'],normalize= False,  title='Matriz de confusión red neuronal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_testset, yhat_5, labels=['A.P.S','DOMICILIO','HOSPITALIZAR','OTRO','OTRO ESTABLECIMIENTO'])\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['A.P.S','DOMICILIO','HOSPITALIZAR','OTRO','OTRO ESTABLECIMIENTO'],normalize= False,  title='Matriz de confusión SVM')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

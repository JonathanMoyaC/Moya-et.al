{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center><font size = 5>Machine Learning models for aiding the decision-making process in emergency departments</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Tabla comparativa de algoritmos<h1>\n",
    "<h3>Descripción</h3>\n",
    "<p>\n",
    "En este script se desarrollará una serie de predicciones basadas en datos del hospital San Juan de Dios Curicó, correspondientes al año 2018 representados por registros de urgencias. El objetivo es predecir, mediante un conjunto de algoritmos, la necesidad de hospitalización de un paciente de urgencias,tomando como input, datos proporcionados por el paciente en la etapa de registro, sus signos vitales registrados en la etapa de triage y el diagnóstico ofrecido por el médico tratante.\n",
    "Se correrán algoritmos de prodicción tales como árboles y bosques de desición, regresión logística, support vector machines y redes neuronales. Para finalmente evaluar el rendimiento de cada algoritmo en términos de la predicción, mediante indicadores tales como Acuraccy, F1-Score, Curva ROC, Índice de Jaccard y logloss\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Descripción de datos\">Descripción de datos</h1>\n",
    "<p>\n",
    "Los datos utilizados fueros proporcionados por el Hospital San Juan de Dios, Curicó, Chile y corresponden a 4.971 registros de pacientes que asistieron a urgencias durante el periodo comprendido entre el 1 de enero de 2018 y agosto de 2019, los datos fueron limpiados y transformados en un script desarrollado previamente\n",
    "<ul>\n",
    "    <li>Datos: <a href=\"https://drive.google.com/open?id=1QmJTDCx060GJw3QHyjl5OhmR4szE8Ojh\" target=\"_blank\">https://drive.google.com/open?id=1QmJTDCx060GJw3QHyjl5OhmR4szE8Ojh</a></li>\n",
    "    <li>Tipo de datos: csv</li>\n",
    "   </ul>\n",
    "<p>\n",
    "Las variables presentes en los datos se describen a continuación:\n",
    "<ul>    \n",
    "   \n",
    "   <li><b>PAC_EDAD</b>: corresponde a la edad del paciente en enteros</li>\n",
    "   <li><b>MOTIVO_CONSULTA</b>: corresponde a la razón por la que el paciente acude al servicio de urgencias string</li>\n",
    "   <li><b>MEDIO</b>: corresponde al medio de llegada, mediante el que el paciente acude al servicio de urgencias</li>\n",
    "   <li><b>SEXO</b>: corresponde al sexo del paciente</li>\n",
    "   <li><b>CAT</b>: corresponde a la categoría de gravedad asignada al paciente en el proceso de Triage</li>\n",
    "   <li><b>PRESION_SIST</b>: corresponde la presión sistólica del paciente </li>\n",
    "   <li><b>PRESION_DIAST</b>: corresponde la presióndiastólica del paciente</li>\n",
    "   <li><b>SATO2</b>: Dato numérico que representa la saturometria del paciente (Nivel de oxigeno en la sangre)</li>\n",
    "   <li><b>TEMPERATURA</b>: corresponde a la temperatura corporal del paciente en el momento de la categorización</li>\n",
    "   <li><b>GLASGOW</b>: corresponde a al nivel registrado por el paciente en la escala Glasgow</li>\n",
    "   <li><b>DM</b>: corresponde si el paciente presenta o no Diabetes Mellitus</li>\n",
    "   <li><b>EVA</b>: corresponde si se aplica al paciente una evaluación de vias aéreas</li>\n",
    "   <li><b>HGT</b>: corresponde a la medida de azucar en la sangre del paciente</li>\n",
    "   <li><b>LCFA</b>: corresponde a si el paciente presenta obstrucción crónica de vías aéreas</li>\n",
    "   <li><b>FR</b>: corresponde a la frecuencia respiratoria del paciente</li>\n",
    "   <li><b>HTA</b>: corresponde a si el paciente posee Hipertención Arterial</li>\n",
    "   <li><b>HORA_INSC</b>: corresponde a la hora en la que el paciente fue categorizado</li>\n",
    "   <li><b>MIN_INSC</b>: corresponde al minuto en que el paciente fue categorizado</li>\n",
    "   <li><b>TIEMPO_ESPERA_CAT</b>: corresponde al tiempo que espera el paciente luego de ser registrado, para ser categorizado</li>\n",
    "      \n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "import sklearn as sk  \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import max_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "#Métodos de tuneo de parámetros\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo= 'df_limpia_dias_hosp.csv'\n",
    "df_urg= pd.read_csv(archivo,encoding='latin-1',sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PAC_EDAD', 'COMUNA', 'PREVISION', 'MOTIVO_CONSULTA',\n",
       "       'MEDIO', 'DESC_EVENTO', 'SEXO', 'SATO2', 'TEMPERATURA', 'GLASGOW', 'DM',\n",
       "       'EVA', 'HGT', 'LCFA', 'FR', 'HTA', 'CAT', 'DESTINO', 'VIOLENCIA',\n",
       "       'PROCEDENCIA', 'DIAGNOSTICO', 'DIAS_HOSP', 'DETALLE_INT',\n",
       "       'TIEMPO_ESPERA_CAT', 'TIEMPO_ESPERA_ATENCION', 'DURACION_ATENCION',\n",
       "       'ESPERA_HOSP_EFECTIVA', 'MES_INSC', 'SEMANA_INSC', 'DIA_MES_INSC',\n",
       "       'DIA_SEMANA_INSC', 'HORA_INSC', 'MIN_INSC', 'DIA_MES_FIN_ATENCION',\n",
       "       'DIA_SEMANA_FIN_ATENCION', 'HORA_INSC_FIN_ATENCION',\n",
       "       'MIN_INSC_FIN_ATENCION', 'MES_HOSP', 'SEMANA_HOSP', 'DIA_MES_HOSP',\n",
       "       'DIA_SEMANA_HOSP', 'PRESION_SIST', 'PRESION_DIAST'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_urg.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionar las variables relevantes para la predicción y asignarselas a la matriz X, de variables independientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_T_hosp = df_urg[[\"PAC_EDAD\",'MOTIVO_CONSULTA','MEDIO', 'SEXO','DESC_EVENTO','GLASGOW', 'DM', 'EVA','HGT', 'LCFA', 'FR', \n",
    "                 'HTA','CAT','DESTINO','DIAS_HOSP','TIEMPO_ESPERA_CAT', 'TIEMPO_ESPERA_ATENCION', 'DURACION_ATENCION',\n",
    "       'ESPERA_HOSP_EFECTIVA', 'MES_INSC', 'SEMANA_INSC', 'DIA_MES_INSC',\n",
    "       'DIA_SEMANA_INSC', 'HORA_INSC', 'MIN_INSC', 'DIA_MES_FIN_ATENCION',\n",
    "       'DIA_SEMANA_FIN_ATENCION', 'HORA_INSC_FIN_ATENCION',\n",
    "       'MIN_INSC_FIN_ATENCION', 'MES_HOSP', 'SEMANA_HOSP', 'DIA_MES_HOSP',\n",
    "       'DIA_SEMANA_HOSP', 'PRESION_SIST', 'PRESION_DIAST']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_T_hosp[[\"PAC_EDAD\",'MOTIVO_CONSULTA','MEDIO', 'SEXO','GLASGOW', 'DM', 'EVA','HGT', 'LCFA', 'FR', \n",
    "                 'HTA','CAT','DESTINO','TIEMPO_ESPERA_CAT', 'TIEMPO_ESPERA_ATENCION', 'DURACION_ATENCION',\n",
    "       'ESPERA_HOSP_EFECTIVA', 'MES_INSC', 'SEMANA_INSC', 'DIA_MES_INSC',\n",
    "       'DIA_SEMANA_INSC', 'HORA_INSC', 'MIN_INSC', 'DIA_MES_FIN_ATENCION',\n",
    "       'DIA_SEMANA_FIN_ATENCION', 'HORA_INSC_FIN_ATENCION',\n",
    "       'MIN_INSC_FIN_ATENCION', 'MES_HOSP', 'SEMANA_HOSP', 'DIA_MES_HOSP',\n",
    "       'DIA_SEMANA_HOSP', 'PRESION_SIST', 'PRESION_DIAST']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[79, 'OTROS, ESPECIFICAR', 'POR SUS PROPIOS MEDIOS', 'FEMENINO',\n",
       "        15.0, 'S', 3.0, 121.0, 'S', 14.0, 'S', 'C3', 'DOMICILIO', 11, 93,\n",
       "        268, 46.0, 5, 21, 23, 2, 17, 1, 23, 2, 23, 13, 3.0, 12.0, 22.0,\n",
       "        3.0, 159.0, 64.0],\n",
       "       [36, 'OTROS, ESPECIFICAR', 'SAMU MOVIL AVANZADO', 'MASCULINO',\n",
       "        15.0, 'N', 5.0, 114.0, 'N', 17.0, 'N', 'C3', 'OTRO', 2, 13, 209,\n",
       "        1315.0, 5, 20, 17, 3, 22, 18, 18, 4, 2, 4, 1.0, 5.0, 30.0, 1.0,\n",
       "        131.0, 84.0]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1 id=\"Preprocesamiento de datos\">Preprocesamiento de datos</h1>\n",
    "<p>\n",
    "Para aplicar el paquete de arboles de desición, los datos deben ser numéricos, en este caso siguen siendo en su mayoría categoricos pero serán transformados a nominales.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesando motivo de consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_motivo_consulta = preprocessing.LabelEncoder()\n",
    "le_motivo_consulta.fit(['OTROS, ESPECIFICAR','DOLOR Y/O MOLESTIAS ABDOMEN'\n",
    ",'PROBLEMAS RESPIRATORIOS','DOLOR Y/O MOLESTIAS TORAX','DOLOR Y/O MOLESTIAS EXTREMIDADES',\n",
    "'ACCIDENTE/TRAUMATISMO OTRO TIPO','ACCIDENTE/TRAUMATISMO EN EL HOGAR', \n",
    "'DIABETES MELLITUS DESCOMPENSADA','VOMITOS',\n",
    "'DOLOR Y/O MOLESTIAS CABEZA Y CUELLO','PRESION ARTERIAL ELEVADA',\n",
    "'ACCIDENTE/TRAUMATISMO VIA PUBLICA','FIEBRE','CONVULSIONES',\n",
    "'CONSTATACION DE LESIONES',\n",
    "'ALCOHOLEMIA + CONST.LESIONES','DIARREA','AGRESION Y/O VIOLENCIA',\n",
    "'MORDEDURA ANIMAL','MORDEDURA ARAÃA','QUEMADURAS','PROCEDIMIENTO DE HEMODINAMIA',\n",
    "'ALCOHOLEMIA','HERIDAS Y/O HEMORRAGIA' ])\n",
    "\n",
    "X[:,1] = le_motivo_consulta.transform(X[:,1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[79, 18, 'POR SUS PROPIOS MEDIOS', ..., 3.0, 159.0, 64.0],\n",
       "       [36, 18, 'SAMU MOVIL AVANZADO', ..., 1.0, 131.0, 84.0],\n",
       "       [37, 18, 'POR SUS PROPIOS MEDIOS', ..., 4.0, 133.0, 64.0],\n",
       "       ...,\n",
       "       [83, 18, 'AMBULANCIA APS', ..., 1.0, 141.0, 61.0],\n",
       "       [41, 1, 'POR SUS PROPIOS MEDIOS', ..., 6.0, 136.0, 81.0],\n",
       "       [82, 18, 'AMBULANCIA HOSPITAL', ..., 3.0, 115.0, 56.0]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesando medio de llegada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_medio = preprocessing.LabelEncoder()\n",
    "le_medio.fit([ 'POR SUS PROPIOS MEDIOS','SAMU MOVIL AVANZADO',\n",
    "'AMBULANCIA APS','AMBULANCIA HOSPITAL','SAMU MOVIL BASICO',\n",
    "'VEHICULO POLICIAL CARABINEROS','OTRO MEDIO TERRESTRE PAGADO',\n",
    "'GENDARMERIA','AMBULANCIA CLINICAS PRIVADAS'])\n",
    "X[:,2] = le_medio.transform(X[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamiento Sexo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_sexo = preprocessing.LabelEncoder()\n",
    "le_sexo.fit([ 'FEMENINO','MASCULINO'])\n",
    "X[:,3] = le_sexo.transform(X[:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamiento DM (Diabetes Mellitus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_DM = preprocessing.LabelEncoder()\n",
    "le_DM.fit([ 'S', 'N','D'])\n",
    "X[:,5] = le_DM.transform(X[:,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamiento LCFA (Limintación crónica del flujo aéreo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_LCFA = preprocessing.LabelEncoder()\n",
    "le_LCFA.fit([ 'S', 'N','D'])\n",
    "X[:,8] = le_LCFA.transform(X[:,8]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamiento HTA (Hipertención Arterial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_HTA = preprocessing.LabelEncoder()\n",
    "le_HTA.fit([ 'S', 'N','D'])\n",
    "X[:,10] = le_HTA.transform(X[:,10]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamiento CAT ( Categoría)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_CAT = preprocessing.LabelEncoder()\n",
    "le_CAT.fit([ 'C1', 'C2','C3','C4','C5'])\n",
    "X[:,11] = le_CAT.transform(X[:,11]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamiento DESTINO (Hospitalizar o no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_DESTINO= preprocessing.LabelEncoder()\n",
    "le_DESTINO.fit(['A.P.S','DOMICILIO','HOSPITALIZAR','OTRO','OTRO ESTABLECIMIENTO','A.P.S.'])\n",
    "X[:,12] = le_DESTINO.transform(X[:,12]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asignación de la variable dependiente a predecir (categoría), al vector y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_T_hosp[\"DIAS_HOSP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1 id=\"Normalización de datos\">Normalización de datos</h1>\n",
    "<p>\n",
    "Para aplicar el paquete de arboles de desición, los datos deben estar en una escala similar, es por ello que optamos por normalizarlos para que los valores estén en un rango entre -2 y 2. Esta medida no altera los resultados aunque si faborece a la eficiencia de los algoritmos\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.92243813,  0.58010589,  0.20755605, -0.8660254 ,  0.26352314,\n",
       "         0.75592895, -0.82911071, -0.4491311 ,  4.96655481, -1.12386049,\n",
       "         0.77988964,  0.75592895, -0.15673224, -0.06931612,  1.41401212,\n",
       "         0.58282432, -1.30025282,  0.79296435,  0.95953793,  0.88861454,\n",
       "        -0.61744679,  0.57781265, -1.73655342,  0.92576862, -0.69708118,\n",
       "         1.33170513, -0.80772554, -0.80255943, -0.74627996,  0.73138838,\n",
       "         0.18058168,  0.44807237, -1.10706919],\n",
       "       [-1.46738398,  0.58010589,  0.70698778,  1.15470054,  0.26352314,\n",
       "        -1.32287566,  0.11668965, -0.54662674, -0.20134682, -0.0238106 ,\n",
       "        -1.15725559,  0.75592895,  1.85466483, -0.12472104, -0.41319884,\n",
       "         0.24055817,  1.62396933,  0.79296435,  0.82039589,  0.1868369 ,\n",
       "        -0.0514539 ,  1.44340748, -0.71215124,  0.33566776,  0.42115322,\n",
       "        -1.57040699, -1.32988394, -1.42053019, -1.24104612,  1.60962471,\n",
       "        -0.88901752, -0.57636457, -0.02528838],\n",
       "       [-1.41180672,  0.58010589,  0.20755605,  1.15470054,  0.26352314,\n",
       "         0.75592895, -0.82911071, -0.17057214, -0.20134682, -0.3904939 ,\n",
       "        -1.15725559, -1.32287566, -1.16243078, -0.12472104, -0.48171926,\n",
       "        -0.91966603,  0.38192383,  0.79296435,  0.68125386, -0.3979778 ,\n",
       "         1.08053189, -0.63402011,  0.61354569, -0.37245327,  0.98027041,\n",
       "        -0.32664465, -1.38790154, -0.49357405, -0.46355643,  0.51182929,\n",
       "         0.71538128, -0.5031905 , -1.10706919],\n",
       "       [ 0.92243813, -0.25637639,  0.20755605, -0.8660254 ,  0.26352314,\n",
       "        -1.32287566, -0.82911071, -0.14271625, -0.20134682, -0.7571772 ,\n",
       "         0.77988964,  0.75592895, -1.16243078, -0.11856494, -0.09343692,\n",
       "        -0.18872478, -1.00760017, -1.00286668, -1.12759259, -0.51494074,\n",
       "         1.64652479,  0.75093162, -0.65189229, -0.49047344,  1.53938761,\n",
       "         1.0553135 , -1.21384874, -1.11154481, -1.17036524, -0.69574567,\n",
       "         0.71538128, -1.30810523, -0.13346646],\n",
       "       [ 0.36666555, -0.25637639,  0.20755605, -0.8660254 ,  0.26352314,\n",
       "         0.75592895, -0.35621053, -0.24021188, -0.20134682, -0.7571772 ,\n",
       "         0.77988964,  0.75592895, -1.16243078, -0.00775509,  1.91649514,\n",
       "        -0.32215057, -1.00529582,  1.39157469,  1.37696403, -0.04708898,\n",
       "         0.514539  ,  0.40469369,  1.51742996, -0.01839275,  0.42115322,\n",
       "         1.0553135 , -1.27186634, -0.18458867, -0.32219467, -1.35442292,\n",
       "         0.18058168, -2.149607  , -1.26933631]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1 id=\"Análisis de componentes principales\">Análisis de componentes principales</h1>\n",
    "<p>\n",
    "Se realizó el análisis de componentes principales con el fin de reducir la dimensionalidad de la base de datos utilizada para la predicción de categoría. El objetivo de reducir la dimensionalidad de la base de datos es agilizar los procesos de entrenamiento y predicción de la categoria de pacientes, además de identificar las variables que presentan una mayor utilidad para esta, descartando las que no aportan indormación a la predicción.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Make an instance of the Model\n",
    "pca = PCA(.95)\n",
    "pca.fit(X)\n",
    "pca.explained_variance_ratio_\n",
    "X.shape\n",
    "#pca.n_components_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1 id=\"Configurando algoritmos\">Configurando algoritmos</h1>\n",
    "<p>\n",
    "En esta sección se definen parámetros necesarios para la correcta aplicación de los algoritmos a implementar, además de seccionar el conjunto de datos en datos de prueba(30%)y de entrenamiento (70%). Los parámetros escogidos pueden ser modificados con el fin de obtener resultados diferentes\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentación del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Árbol de desición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21., 20.,  3.,  3., 12., 10.,  3., 19., 32., 32.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "DT= DecisionTreeRegressor(random_state=0)\n",
    "DT.fit(X_trainset,y_trainset)\n",
    "yhat_1 = DT.predict(X_testset)\n",
    "DT_CV = cross_val_score(DT, X, y, cv=10)\n",
    "DT_R2=round(DT.score(X_testset, y_testset),4)\n",
    "DT_MAX=max_error( y_testset,yhat_1)\n",
    "DT_MAD=mean_absolute_error( y_testset,yhat_1)\n",
    "DT_MSE =round(mean_squared_error(y_testset,yhat_1),4)\n",
    "DT_r22= round(r2_score(y_testset,yhat_1),4)\n",
    "DT_r22\n",
    "yhat_1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31     8.0\n",
       "32     0.0\n",
       "23     4.0\n",
       "60    29.0\n",
       "8     36.0\n",
       "6     21.0\n",
       "52     3.0\n",
       "9     36.0\n",
       "12     4.0\n",
       "27     5.0\n",
       "Name: DIAS_HOSP, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_testset[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 66 candidates, totalling 198 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 198 out of 198 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse',\n",
       "                                             max_depth=None, max_features=None,\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             presort='deprecated',\n",
       "                                             random_state=42, splitter='best'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'criterion': ['mse', 'friedman_mse', 'mae'],\n",
       "                          'max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20])},\n",
       "                         {'min_samples_leaf': [1, 5, 10, 20, 50, 100]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_parameters = [{'criterion': ['mse', 'friedman_mse', 'mae'], 'max_depth': np.arange(1, 21)},{'min_samples_leaf': [1, 5, 10, 20, 50, 100]}]\n",
    "DT_GS = GridSearchCV(DecisionTreeRegressor(random_state=42), DT_parameters, verbose=1, cv=3)\n",
    "DT_GS.fit(X_trainset,y_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=20, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=42, splitter='best')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1483"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_1_GS= DT_GS.predict(X_testset)\n",
    "DT_R2_GS=round(DT_GS.score(X_testset, y_testset),4)\n",
    "DT_MAX_GS=max_error( y_testset,yhat_1_GS)\n",
    "DT_MAD_GS=mean_absolute_error( y_testset,yhat_1_GS)\n",
    "DT_MSE_GS =round(mean_squared_error(y_testset,yhat_1_GS),4)\n",
    "DT_r22_GS= round(r2_score(y_testset,yhat_1_GS),4)\n",
    "DT_r22_GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  índices de rendimiento  Árboles de decisión  Grid Search\n",
      "0                    R^2              -1.9545    -0.148300\n",
      "1              MAX error              63.0000    20.437500\n",
      "2                    MAD              14.6250    11.279018\n",
      "3                    MSE             388.8750   151.144100\n"
     ]
    }
   ],
   "source": [
    "resultados_DT = {'índices de rendimiento':['R^2','MAX error','MAD','MSE'],\n",
    "             'Árboles de decisión':[DT_R2,DT_MAX,DT_MAD,DT_MSE],\n",
    "             'Grid Search':[DT_R2_GS,DT_MAX_GS,DT_MAD_GS,DT_MSE_GS]}\n",
    "Tabla_resultados_DT=pd.DataFrame(resultados_DT)\n",
    "print(Tabla_resultados_DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bosque de desición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197.9246"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RF= RandomForestRegressor(max_depth=2, random_state=0)\n",
    "RF.fit(X_trainset,y_trainset)\n",
    "yhat_2 = RF.predict(X_testset)\n",
    "RF_R2=round(RF.score(X_testset, y_testset),4)\n",
    "RF_MAX=round(max_error( y_testset,yhat_2),4)\n",
    "RF_MAD=round(mean_absolute_error( y_testset,yhat_2),4)\n",
    "RF_MSE =round(mean_squared_error(y_testset,yhat_2),4)\n",
    "RF_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=2,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=0,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'criterion': ['mse', 'friedman_mse', 'mae'],\n",
       "                         'max_depth': [2, 3, 4, 5, 6, 7, 8],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [200, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_parameters ={ 'n_estimators': [200, 500],'max_features': ['auto', 'sqrt', 'log2'],'max_depth' : [2,3,4,5,6,7,8],'criterion' :['mse', 'friedman_mse', 'mae']}\n",
    "RF_GS = GridSearchCV(estimator=RF,param_grid=RF_parameters, cv= 3)\n",
    "RF_GS.fit(X_trainset,y_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='entropy', max_depth=8, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.9803"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_2_GS= RF_GS.predict(X_testset)\n",
    "RF_R2_GS=round(RF.score(X_testset, y_testset),4)\n",
    "RF_MAX_GS=round(max_error( y_testset,yhat_2_GS),4)\n",
    "RF_MAD_GS=round(mean_absolute_error( y_testset,yhat_2_GS),4)\n",
    "RF_MSE_GS =round(mean_squared_error(y_testset,yhat_2_GS),4)\n",
    "RF_MSE_GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  índices de rendimiento  Bosques de decisión  Grid Search\n",
      "0                    R^2              -0.5037      -0.5037\n",
      "1              MAX error              27.1926      27.0125\n",
      "2                    MAD              12.1118      10.7566\n",
      "3                    MSE             197.9246     160.9803\n"
     ]
    }
   ],
   "source": [
    "resultados_RF = {'índices de rendimiento':['R^2','MAX error','MAD','MSE'],\n",
    "             'Bosques de decisión':[RF_R2,RF_MAX,RF_MAD,RF_MSE],\n",
    "             'Grid Search':[RF_R2_GS,RF_MAX_GS,RF_MAD_GS,RF_MSE_GS]}\n",
    "Tabla_resultados_RF=pd.DataFrame(resultados_RF)\n",
    "print(Tabla_resultados_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresión logística (multi-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213.375"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LR = LogisticRegression(C=0.01, solver='newton-cg',penalty='l2').fit(X_trainset,y_trainset)\n",
    "yhat_3= LR.predict(X_testset)\n",
    "LR_R2=round(LR.score(X_testset, y_testset),4)\n",
    "LR_MAX=round(max_error( y_testset,yhat_3),4)\n",
    "LR_MAD=round(mean_absolute_error( y_testset,yhat_3),4)\n",
    "LR_MSE =round(mean_squared_error(y_testset,yhat_3),4)\n",
    "LR_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\jmoya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=LogisticRegression(C=0.01, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='newton-cg',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': array([   1.25892541,    3.83118685,   11.65914401,   35.48133892,\n",
       "        107.97751623,  328.59932476, 1000.        ]),\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_parameters ={'C':np.logspace(0.1,3,7), 'penalty':['l1', 'l2', 'elasticnet'],}\n",
    "LR_GS = GridSearchCV(estimator=LR,param_grid=LR_parameters, cv= 3,verbose=0,)\n",
    "LR_GS.fit(X_trainset,y_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.2589254117941673, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180.8333"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_3_GS= LR_GS.predict(X_testset)\n",
    "LR_R2_GS=round(LR.score(X_testset, y_testset),4)\n",
    "LR_MAX_GS=round(max_error( y_testset,yhat_3_GS),4)\n",
    "LR_MAD_GS=round(mean_absolute_error( y_testset,yhat_3_GS),4)\n",
    "LR_MSE_GS =round(mean_squared_error(y_testset,yhat_3_GS),4)\n",
    "LR_MSE_GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  índices de rendimiento  Regresión Logística  Grid Search\n",
      "0                    R^2               0.1667       0.1667\n",
      "1              MAX error              33.0000      30.0000\n",
      "2                    MAD               9.5417       9.7500\n",
      "3                    MSE             213.3750     180.8333\n"
     ]
    }
   ],
   "source": [
    "resultados_LR = {'índices de rendimiento':['R^2','MAX error','MAD','MSE'],\n",
    "             'Regresión Logística':[LR_R2,LR_MAX,LR_MAD,LR_MSE],\n",
    "             'Grid Search':[LR_R2_GS,LR_MAX_GS,LR_MAD_GS,LR_MSE_GS]}\n",
    "Tabla_resultados_LR=pd.DataFrame(resultados_LR)\n",
    "print(Tabla_resultados_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresión Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286.5444"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "LssR = linear_model.Lasso(alpha=0.1).fit(X_trainset,y_trainset)\n",
    "yhat_6= LssR.predict(X_testset)\n",
    "LssR_R2=round(LssR.score(X_testset, y_testset),4)\n",
    "LssR_MAX=round(max_error( y_testset,yhat_6),4)\n",
    "LssR_MAD=round(mean_absolute_error( y_testset,yhat_6),4)\n",
    "LssR_MSE =round(mean_squared_error(y_testset,yhat_6),4)\n",
    "LssR_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=Lasso(alpha=0.1, copy_X=True, fit_intercept=True,\n",
       "                             max_iter=1000, normalize=False, positive=False,\n",
       "                             precompute=False, random_state=None,\n",
       "                             selection='cyclic', tol=0.0001, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'alpha': [0.005, 0.02, 0.03, 0.05, 0.06]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LssR_parameters ={'alpha':[0.005, 0.02, 0.03, 0.05, 0.06]}\n",
    "LssR_GS = GridSearchCV(estimator=LssR,param_grid=LssR_parameters, cv= 3, verbose=True, n_jobs=-1)\n",
    "LssR_GS.fit(X_trainset,y_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.06, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LssR_GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296.473"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_6_GS= LssR_GS.predict(X_testset)\n",
    "LssR_R2_GS=round(LssR.score(X_testset, y_testset),4)\n",
    "LssR_MAX_GS=round(max_error( y_testset,yhat_6_GS),4)\n",
    "LssR_MAD_GS=round(mean_absolute_error( y_testset,yhat_6_GS),4)\n",
    "LssR_MSE_GS =round(mean_squared_error(y_testset,yhat_6_GS),4)\n",
    "LssR_MSE_GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  índices de rendimiento  Regresión Lasso  Grid Search\n",
      "0                    R^2          -1.1770      -1.1770\n",
      "1              MAX error          31.1565      29.9883\n",
      "2                    MAD          15.1231      15.3464\n",
      "3                    MSE         286.5444     296.4730\n"
     ]
    }
   ],
   "source": [
    "resultados_LssR = {'índices de rendimiento':['R^2','MAX error','MAD','MSE'],\n",
    "             'Regresión Lasso':[LssR_R2,LssR_MAX,LssR_MAD,LssR_MSE],\n",
    "             'Grid Search':[LssR_R2_GS,LssR_MAX_GS,LssR_MAD_GS,LssR_MSE_GS]}\n",
    "Tabla_resultados_LssR=pd.DataFrame(resultados_LssR)\n",
    "print(Tabla_resultados_LssR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179.695"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "NN = MLPRegressor(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1).fit(X_trainset,y_trainset)\n",
    "yhat_4 = NN.predict(X_testset)\n",
    "NN_R2=round(NN.score(X_testset, y_testset),4)\n",
    "NN_MAX=round(max_error( y_testset,yhat_4),4)\n",
    "NN_MAD=round(mean_absolute_error( y_testset,yhat_4),4)\n",
    "NN_MSE =round(mean_squared_error(y_testset,yhat_4),4)\n",
    "NN_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1260 candidates, totalling 3780 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   32.8s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2244 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3780 out of 3780 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=MLPRegressor(activation='relu', alpha=1e-05,\n",
       "                                    batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
       "                                    early_stopping=False, epsilon=1e-08,\n",
       "                                    hidden_layer_sizes=(5, 2),\n",
       "                                    learning_rate='constant',\n",
       "                                    learning_rate_init=0.001, max_fun=15000,\n",
       "                                    max_iter=200, momentum=0.9,\n",
       "                                    n_iter_no_change=10,\n",
       "                                    nesterovs_momentum=True, power_t=0.5,\n",
       "                                    random_state=1,...\n",
       "                                    validation_fraction=0.1, verbose=False,\n",
       "                                    warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'alpha': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06]),\n",
       "                         'hidden_layer_sizes': array([ 5,  6,  7,  8,  9, 10, 11]),\n",
       "                         'max_iter': [500, 1000, 1500],\n",
       "                         'random_state': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         'solver': ['lbfgs']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=True)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_parameters ={'solver': ['lbfgs'], 'max_iter': [500,1000,1500], 'alpha': 10.0 ** -np.arange(1, 7), 'hidden_layer_sizes':np.arange(5, 12), 'random_state':[0,1,2,3,4,5,6,7,8,9]}\n",
    "NN_GS = GridSearchCV(estimator=NN,param_grid=NN_parameters, cv= 3, verbose=True, n_jobs=-1)\n",
    "NN_GS.fit(X_trainset,y_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=6, learning_rate='constant',\n",
       "             learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
       "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "             power_t=0.5, random_state=5, shuffle=True, solver='lbfgs',\n",
       "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284.9929"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_4_GS= NN_GS.predict(X_testset)\n",
    "NN_R2_GS=round(NN.score(X_testset, y_testset),4)\n",
    "NN_MAX_GS=round(max_error( y_testset,yhat_4_GS),4)\n",
    "NN_MAD_GS=round(mean_absolute_error( y_testset,yhat_4_GS),4)\n",
    "NN_MSE_GS =round(mean_squared_error(y_testset,yhat_4_GS),4)\n",
    "NN_MSE_GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  índices de rendimiento  Red Neuronal  Grid Search\n",
      "0                    R^2       -0.3652      -0.3652\n",
      "1              MAX error       29.3941      55.7347\n",
      "2                    MAD       10.1660      11.9096\n",
      "3                    MSE      179.6950     284.9929\n"
     ]
    }
   ],
   "source": [
    "resultados_NN = {'índices de rendimiento':['R^2','MAX error','MAD','MSE'],\n",
    "             'Red Neuronal':[NN_R2,NN_MAX,NN_MAD,NN_MSE],\n",
    "             'Grid Search':[NN_R2_GS,NN_MAX_GS,NN_MAD_GS,NN_MSE_GS]}\n",
    "Tabla_resultados_NN=pd.DataFrame(resultados_NN)\n",
    "print(Tabla_resultados_NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.8974"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "SVM = LinearSVR(random_state=0, tol=1e-5)\n",
    "SVM.fit(X_trainset, y_trainset) \n",
    "yhat_5 = SVM.predict(X_testset)\n",
    "SVM_R2=round(SVM.score(X_testset, y_testset),4)\n",
    "SVM_MAX=round(max_error( y_testset,yhat_5),4)\n",
    "SVM_MAD=round(mean_absolute_error( y_testset,yhat_5),4)\n",
    "SVM_MSE =round(mean_squared_error(y_testset,yhat_5),4)\n",
    "SVM_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=LinearSVR(C=1.0, dual=True, epsilon=0.0,\n",
       "                                 fit_intercept=True, intercept_scaling=1.0,\n",
       "                                 loss='epsilon_insensitive', max_iter=1000,\n",
       "                                 random_state=0, tol=1e-05, verbose=0),\n",
       "             iid='deprecated', n_jobs=-1, param_grid={'C': [0.1, 1, 10, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=True)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_parameters ={'C': [0.1,1, 10, 100]}\n",
    "SVM_GS = GridSearchCV(estimator=SVM,param_grid=SVM_parameters, cv= 3, verbose=True, n_jobs=-1)\n",
    "SVM_GS.fit(X_trainset,y_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVR(C=1, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "          intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "          random_state=0, tol=1e-05, verbose=0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.8974"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_5_GS= SVM_GS.predict(X_testset)\n",
    "SVM_R2_GS=round(SVM.score(X_testset, y_testset),4)\n",
    "SVM_MAX_GS=round(max_error( y_testset,yhat_5_GS),4)\n",
    "SVM_MAD_GS=round(mean_absolute_error( y_testset,yhat_5_GS),4)\n",
    "SVM_MSE_GS =round(mean_squared_error(y_testset,yhat_5_GS),4)\n",
    "SVM_MSE_GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  índices de rendimiento  Red Neuronal  Grid Search\n",
      "0                    R^2       -0.1540      -0.1540\n",
      "1              MAX error       26.1806      26.1806\n",
      "2                    MAD        9.9512       9.9512\n",
      "3                    MSE      151.8974     151.8974\n"
     ]
    }
   ],
   "source": [
    "resultados_SVM = {'índices de rendimiento':['R^2','MAX error','MAD','MSE'],\n",
    "             'Red Neuronal':[SVM_R2,SVM_MAX,SVM_MAD,SVM_MSE],\n",
    "             'Grid Search':[SVM_R2_GS,SVM_MAX_GS,SVM_MAD_GS,SVM_MSE_GS]}\n",
    "Tabla_resultados_SVM=pd.DataFrame(resultados_SVM)\n",
    "print(Tabla_resultados_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Algoritmos de regresión     R^2  Max error      MAD       MSE\n",
      "0     Árboles de decisión -1.9545    63.0000  14.6250  388.8750\n",
      "1     Bosques de decisión -0.5037    27.1926  12.1118  197.9246\n",
      "2     Regresión Logística  0.1667    33.0000   9.5417  213.3750\n",
      "3         Regresión Lasso -1.1770    31.1565  15.1231  286.5444\n",
      "4            Red Neuronal -0.3652    29.3941  10.1660  179.6950\n",
      "5  Support Vector Machine -0.1540    26.1806   9.9512  151.8974\n"
     ]
    }
   ],
   "source": [
    "resultados = {'Algoritmos de regresión':['Árboles de decisión','Bosques de decisión','Regresión Logística','Regresión Lasso','Red Neuronal','Support Vector Machine'],\n",
    "             'R^2':[DT_R2,RF_R2,LR_R2,LssR_R2,NN_R2,SVM_R2],\n",
    "             'Max error':[DT_MAX,RF_MAX,LR_MAX,LssR_MAX,NN_MAX,SVM_MAX],\n",
    "             'MAD':[DT_MAD,RF_MAD,LR_MAD,LssR_MAD,NN_MAD,SVM_MAD],\n",
    "             'MSE':[DT_MSE,RF_MSE,LR_MSE,LssR_MSE,NN_MSE,SVM_MSE]}\n",
    "Tabla_resultados=pd.DataFrame(resultados)\n",
    "print(Tabla_resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
